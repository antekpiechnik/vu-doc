\section{Discussion of results}
In this chapter we will discuss and compare the results achieved as well as their possible influence on the NoTube project. We will also mention work that might be performed in the future in order to extend this research further.

\subsection{Comparison and analysis of the results}
For both the \textit{YouTube} as well as \textit{Twitter} services, it was extremely challenging to achieve results of
quality. Results varied from quite accurate to containing subjects completely irrelevant to the user being surveyed.

\paragraph{Userbase}
Perhaps the biggest influence on the quality of the results has been the way people use the services researched.
In \textit{YouTube}, users tend to XXXX. On the other hand, Twitter users usually tend to update their statuses
with various information, very rarely regarding TV activities. From the users being analyzed by this poll, a very
little amount of tweets regarded media subjects. Given the fact that those users tweeted on multiple other subjects,
a chance of recognizing an entity in the right context is relatively tiny.

\paragraph{Accuracy of known topics recognition}
Both data sources analyzed returned only a small part of correct topics recognized. In Twitter this score has
averaged around \textit{25\%}, whereas in YouTube, XXXX. This means that the data, in small amounts however, is actually present
within those streams. However in order to be able to extract them with greater accuracy, more advanced methods have
to be used.

\paragraph{Accuracy of the preference scores}
Within the properly recognized subjects, methods used by the \textit{Twitter} profiler have proved to be effective enough
to be able to specify whether the user simply knows the subject or could identify preference towards it with quite a high
rate (more than \textit{75\%} preference scores were correct), despite being quite trivial. This also originates in the fact
that Twitter users tend to Tweet about things they like. XXXX

\subsection{Possible influence on the NoTube project}

The \textit{NoTube} project is able to personalize recommendations for TV programmes for a user. In order to maximize
it's recommending potential, it needs to aggregate data from different sources.

Both \textit{YouTube} and \textit{Twitter} certainly do contain information useful for this topic. However, in order to be
able to fully use it's potential, the recommender would have to incorporate more advanced methods for media topics
recognition and also require an evaluation of information extracted from those streams based on the current profile
of a given user. Given the little amounts of media-related information in some of user's streams, results obtained from incorporating such methods might prove not worth the cost of their implementation.

The \textit{NoTube} target might be users who very rarely employ Twitter or YouTube for expressing their
opinions on media subjects. Moreover, should any integration with YouTube or Twitter appear within the project, the TV-related
part of a user's stream might become automatically generated, making use of such services-based recommender slightly obsolete.

On the other hand, there seem to be uses for such recommenders. Provided a user updates his Twitter information with enough
media--related information, a recommender based on information from this service could be helpful for creating initial
user profiles as well as be able to provide a teaser of the project's functionality.

\subsection{Evolution of the Userbase}
\paragraph{YouTube}
\begin{itemize}
  \item what will the influence of GoogleTV be ?
  \item what if YouTube starts offering TV shows ?
\end{itemize}

\paragraph{Twitter}
\begin{itemize}
  \item influence of the announced Twitter-provided enrichments ?
  \item influence of advertising on Twitter ?
  \item integration with more services ?
\end{itemize}

\subsection{Future work}

\subsubsection{Possible improvements of subject recognition methods}

\paragraph{Context/Semantic-based searching for removing accidental matches}
In order to enhance the accuracy of entities recognized within a user's Twitter stream, one could employ search methods
based on analyzing a single tweet's context regarding other topics related to the media field using semantic services.
However, this approach could be much slower for multiple tweets within a significant userbase.

\paragraph{Comparison of TV show entities against more natural language corpora}
In order to minimize the amount of \textit{false positives} matched in a user's stream, different entities' names and aliases
should be ran against corpora strictly related to the field of research (such as TV or other media related newspaper/magazine
articles). Using this approach while also using semantic recognition could decrease recommender's speed even further. The
eventual product of employing such approach would have to be measured, as simple methods of such ''ranking'' proved not effective enough (despite being quite promising).

\subsubsection{Research into other services}
\begin{itemize}
  \item Facebook?
  \item Myspace?
\end{itemize}