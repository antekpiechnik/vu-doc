\section{Potential uses and future work}

In this section, we discuss the future of our work in context of the current
trends among social web services. We also point out potential improvements for
our algorithms.

\subsection{Possible influence on the NoTube project}

The \textit{NoTube} project is able to personalize recommendations for TV
programmes for a user. In order to maximize its recommending potential, it
needs to aggregate data from different sources. Once the project becomes such a
source, the recommender would have access to a much wider set of data,
collected by the NoTube project itself.

Both \textit{YouTube} and \textit{Twitter} certainly do contain information
useful for this topic. However, for limited sets of data (non-active
Twitter/YouTube users), the recommender might need to 
incorporate more advanced methods for media topics recognition or maybe require
an evaluation of information extracted from those streams by the user.
Given the little amounts of media-related information in some of user's
streams, results obtained from incorporating such methods might prove useful
only for the cold-start situation, that is: to estimate the user's interests
very roughly in hope to gather more data during user's activity.

However, for very active Twitter and YouTube users, the profiles extracted
might be rich enough to be very useful for recommender systems. The amount of
information generated would be a considerable set to run a recommender against.

\subsection{Evolution of the Userbase}

Since the userbase of social network is constantly changing, we would like to
discuss the possible changes and their influence on this research.

\paragraph{YouTube}

YouTube users tend not to watch many videos related to the TV Shows, we would
like to consider situations where this state might change. An obvious case
appears with Google (the owner of YouTube) planning on offering GoogleTV in the
fall of 2010. Such a move might create opportunities for users to integrate
this service with YouTube, changing the way users employ YouTube.

Furthermore, should YouTube follow the example of services like \textit{Hulu}
and start offering streaming of TV-Shows, it would immediately allow people to
comment, share their preferences, making it a perfect source for extracting
users' preferences.

\paragraph{Twitter}

Recently Twitter has announced plans of bringing advertising (e.g. in a form of
\textit{Promoted Tweets}) to users' stream.  By retweeting such advertisements,
users might show some interest in additional subjects mentioned in their
streams.

What is far more interesting, is the idea of providing Twitter-based
enrichments (called the Annotations) that Twitter has announced\footnote{http://blog.twitter.com/2010/05/twitter-platform.html},
bringing semantic-like concepts into all tweets and making users able to
retweet those concepts and find out more about them. This could increase
the probability of matching entities correctly.

On the other hand, it seems like Twitter will still mostly be used to update
information on current activities and, in contrast to YouTube, we do not think
this will change soon.

\subsection{Future work}

\subsubsection{Context/Semantic-based entity recognition}

\paragraph{Removing more accidental matches}

In order to enhance the accuracy of entities recognized within a user's Twitter
stream, one could employ search methods based on analyzing a single tweet's
context regarding other topics related to the media field using semantic
services.  However, this approach could be much slower for multiple tweets
within a significant userbase.

\paragraph{Entity ambiguity}

Some entity categories (such as \textit{TV Actors}) can be ambiguous (such as \textbf{John Terry the actor} and \textbf{John Terry the footballer}). Such situations
would require us to use additional methods (such as context-based reasoning) in order to accurately identify the entity in question.

\subsubsection{Comparison of TV show entities against more natural language corpora}

In addition to methods described in section 6.3, to further minimize the amount of \textit{false positives}
matched in a user's stream, different entities' names and aliases should be ran against corpora
that are \textit{strictly related to the topic of the recommender}, (such as TV or other media related
newspaper/magazine articles). Using this approach while also using semantic
recognition could decrease recommender's speed even further.

\subsubsection{Research into other services}

In order to be able to perform more analaysis, it might be useful to perform
research into other services, such as \textit{Facebook} or \textit{MySpace}.
There however are much more private networks, where users tend not to share
their information publicly. This might make them less accessible, but due to a
great number of users, they might contain useful data.

\subsection{Conclusions}

The work done for this project let us better understand the actual content
hidden in data gathered by the two analyzed web services. The tools that we
prepared might prove useful for collecting data for use in recommender systems.

The research questions that we posed let us focus on the ways to extract most
useful information available. We learned that while basic extracting of the
user profiles is relatively easy, it is extremely challenging to guarantee high
quality of the results. We also identified two main obstructions as the
scarcity of data available for a single user and the pervasiveness of some
entities' names in other contexts.
