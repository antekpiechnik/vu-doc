\section{Potential uses and future work}

In this section, we discuss the future of our work in context of the current
trends among social web services. We also point out potential improvements for
our algorithms.

\subsection{Application in the NoTube project}

NoTube is a European project that aims to connect TV and the Web through
semantics. Currently, user activity on the Web has little or no influence on
what you see on TV and visa versa. In NoTube bits and pieces of data that are
scattered around on the Web are accumulated and used to personalize TV. Userdata
is collected from social sites, such as Facebook, YouTube and Twitter, and used
to generate a user profile. Data on TV programs is collected from online program
guides and enriched with semantics from the Linked Open Data cloud (LOD). The
background data available in LOD is employed to find links between the user's
interests and TV programs. An integral part of the project is the user front-end
interface, which is used to present the prepared recommendations to the user,
and let him actually watch the shows. This is another source of data useful as
an input to the recommender module.

Both \textit{YouTube} and \textit{Twitter} certainly do contain information
useful for this topic. However, for limited sets of data (non-active
Twitter/YouTube users), the recommender might need to 
incorporate more advanced methods for media topics recognition or maybe require
an evaluation of information extracted from those streams by the user.
Given the little amounts of media-related information in some of user's
streams, results obtained from incorporating such methods might prove useful
only for the cold-start situation, that is: to estimate the user's interests
very roughly in hope to gather more data during user's activity.

However, for very active Twitter and YouTube users, the profiles extracted
might be rich enough to be very useful for recommender systems. The amount of
information generated would be a considerable set to run a recommender against.

\subsection{Evolution of the Userbase}

Since the userbase of social network is constantly changing, we would like to
discuss the possible changes and their influence on this research.

\paragraph{YouTube}


In the recent years, YouTube officially incorporated television shows on their
site \cite{youtube-tv-shows} and a plethora of shows is uploaded by the users
every day, which indicates that increasing number of users uses this service to
watch their favourite TV shows. This number would possibly increase even more
when Google begins to offer GoogleTV in the
fall of 2010. Such a move might create opportunities for users to integrate
this service with YouTube, changing the way users employ YouTube.

Furthermore, should YouTube follow the example of services like \textit{Hulu}
and start offering streaming of TV shows, its user interaction data would become
directly applicable for profile generation.

\paragraph{Twitter}

Recently Twitter has announced plans of bringing advertising (\eg in a form of
\textit{Promoted Tweets}) to users' stream.  By retweeting such advertisements,
users might show some interest in additional subjects mentioned in their
streams.

Another interesting field for research is analysis of the Twitter-provided
enrichments (called the Annotations) that Twitter has announced\footnote{http://blog.twitter.com/2010/05/twitter-platform.html},
bringing semantic-like concepts into all tweets and making users able to
retweet those concepts and find out more about them. This could increase
the probability of matching entities correctly.

On the other hand, it seems like Twitter will still mostly be used to update
information on current activities and, in contrast to YouTube, we do not think
this will change soon.

\subsection{Future developments}

We collected a list of techniques the application of which would be an
interesting topic for further research. Some of them are listed below.

\subsubsection{Context/Semantic-based entity recognition}

\paragraph{Removing more accidental matches}

In order to enhance the accuracy of entities recognized within a user's Twitter
stream, one could employ search methods based on analyzing a single tweet's
context regarding other topics related to the media field using semantic
services.  However, this approach could be much slower for multiple tweets
within a significant userbase.

\paragraph{Entity ambiguity}

Some entity categories (such as \textit{TV Actors}) can be ambiguous (such as \textbf{John Terry the actor} and \textbf{John Terry the footballer}). Such situations
would require us to use additional methods (such as context-based reasoning) in order to accurately identify the entity in question.

\subsubsection{Comparison of TV show entities against more natural language corpora}

In addition to methods described in section 6.3, to further minimize the amount of \textit{false positives}
matched in a user's stream, different entities' names and aliases should be ran against corpora
that are strictly \textbf{unrelated} to the topic of the recommender, (such as TV or other media related
newspaper/magazine articles). This might further increase it's accuracy when filtering the accidental
matches. Using this approach while also using semantic recognition could decrease recommender's
speed even further.

\subsubsection{Research into other services}

In order to be able to perform more analysis, it might be useful to perform
research into other services, such as \textit{Facebook} or \textit{MySpace}.
There however are much more private networks, where users tend not to share
their information publicly. This might make them less accessible, but due to a
great number of users, they might contain useful data.

\subsection{Conclusions}

During this research, we have analyzed data contained in two widely used web
services: Twitter and YouTube, and implemented software, that prepares a user
profile based on this data and vocabularies created within the freebase project.
We analyzed the pervasiveness of media-related entities within each service and
discovered that structured data from YouTube, while giving more results, lacks
the quality of the information (level of interest) that might be reached basing
on Twitter data. The profile generators we prepared will be used in the NoTube
project -- a semantic approach to Television.

The research questions that we posed let us focus on the ways to extract most
useful information available. We learned that while basic extracting of the
user profiles is relatively easy, it is extremely challenging to guarantee high
quality of the results. We also identified two main obstructions as the
scarcity of data available for a single user and the pervasiveness of some
entities' names in other contexts.

Additional research performed in parallel, let us understand better the ways, in
which Twitter and YouTube services are used. We discovered the ''long tail''
nature of popularity of such YouTube functions as favourites, subscriptions and
uploads (meaning: a small group of users gathers a big sample, while for large
majority the usage of these functions remains relatively low). We also analyzed
the ways of mentioning media-related items in the Twitter streams: either by the
full name, the hashtag or by the acronym. We discovered a tendency for the
Twitter updates to contain more than one reference to media-related content.

We expect our research will be useful for people working with social media
content. The measurements we performed might prove of a value not only for
semantic web researchers but also for people analyzing rather social dimension
and the behavioural patterns.
