\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{multirow}
\usepackage{verbatim}
\usepackage[pdftex]{graphicx}
\usepackage{subfigure}


\begin{document}
\title{Profiling users media preferences based on social network data streams}
\author{Konrad Delong \and Antoni Piechnik}
\date{June 17 2010}

\maketitle

\begin{abstract} Social networks have been becoming hugely popular over the last
years. With enormous number of people sharing information about their lives,
they are now a great source of information about their interests. Based on both
structured data (such as the social aspect of YouTube) as well as unstructured
(Twitter), we will be trying to find out how accurately we can profile user's
preferences for it to be usable in a real life project (NoTube).
\end{abstract}

\include{introduction}

\include{data_sources}

\include{youtube_extracting}

\include{twitter_extracting}

\include{evaluation}

\section{Discussion of results}

\section{Implementation details}

\subsection{Technologies used in Twitter research}
\subsubsection{Language}
Most processing has been done using the \textit{Ruby} language. The NoTube tubelets/reasonlets will be implemented in either pure \textit{Java} or \textit{JRuby}.
\subsubsection{Tools}
Twitter API requests are been handled via the OAuth protocol and provided in a JSON-based stream form. Only the newest tweets for the pre-selected Twitter usernames are downloaded. The entities definitions and semantics are provided by the FreeBase database REST interface. All the processing occurs locally on the pre-loaded Twitter data. \\ Ruby gems used include:
\begin{itemize}
  \item \textit{bdb} from mattbauer - a BerkeleyDB wrapper for Ruby
  \item \textit{twitter} from jnunemaker - a wrapper around the Twitter API
  \item \textit{ferret} - full text search engine written in Ruby
  \item \textit{ken} from michael-aufreiter - wrapper for the freebase.org API
\end{itemize}
\subsubsection{Storage}
Due to Twitter API request rate limiting, tweets have been aggregated in a local
\textit{Berkeley DB} database instance providing a fast and easy key-value
information retrieval. Since great amount of data needs to be processed, a full
text search engine has been used, which greatly increased the searching time. In
this case, we decided on using \textit{ferret} - a Ruby implementation of a
full-text search engine (similar to Apache's \textit{Lucene}).

\section{Related work (work in progress)}

\subsection{Hunch.com}
\subsubsection{Goal}
\textit{Hunch.com} is a service offering recommendations on different topics based on a user's twitter data. It predicts preferences in forms of small questions and is then able to recommend a product or a solution to a problem that is represented with a \textit{Topic} on the site. \textit{Hunch.com} seems to be more commercial-oriented, e.g. providing users with links to online stores with products they are recommending.

\subsubsection{Approach}
The application can create recommendations based solely on user's twitter data (mostly people they follow). However, when not that much data is available, it requires input from users in order to make future predictions more accurate. It also seems to be covering topics a bit broader than the NoTube project.
\textit{Hunch.com} does not provide information on how the recommender system works, although it provides an API for accessing their data.
Hunch is able to adapt to much more different topics, and it not necessarily focuses on their semantics (rather on what similar people simply like).

\subsection{Open Graph}
\subsubsection{Goal}
\textit{Open Graph} has been introduced by Facebook in order to create a system for stating preferences by clicking a \textit{Like} button displayed on different pages. Due to the popularity of Facebook, it certainly will become a major source of data for any kind of recommender systems.

\subsubsection{Approach}
\textit{Open Graph} provides developers with an API for accessing it's data. It is restricted by a given user's privacy settings.
It aggregates information based on the sites the user clicks the button on, thus being able to gather a great deal of information. \textit{Open Graph} does not seem to be also approaching any kind of Twitter data, making our Twitter profiling methods a completely separate topic.
The biggest disadvantage is no \textit{Dislike} button, making it impossible for a user to state negative opinion on a given subject.
\end{document}
