\documentclass{article}

\begin{document}
\title{Profiling users media preferences based on social network data streams}
\author{Konrad Delong \and Antoni Piechnik}
\date{April 6 2010}

\maketitle

\begin{abstract}
Social networks have been becoming hugely popular over the last years. With enormous amounts of people sharing information about their lives, they are now a great source of information about their interests. Based on both structured data (such as the social aspect of YouTube) as well as unstructured (Twitter), we will be trying to find out how accurately we can profile user's preferences for it to be usable in a real life project (NoTube).
\end{abstract}

\section{Problem statement}
The NoTube project bases its recommendation on aggregating, extracting and analyzing user activities. Since media oriented web services (such as YouTube) hold a great amount of information regarding a users' video viewing preferences, it might provide a great deal of additional information for profiling NoTube users. General activity services (social networks like Facebook or Twitter) detail the lives of its users, it is very likely that they also contain information regarding their tv watching activities.

The most important question is what user data we can collect from both structured and unstructured social applications? When it comes to YouTube, users can mark videos as favorite, subscribe to other users' channels and comment on videos. From all that information we can not only extract the titles of videos they are interested in but also tags describing them as well as relations to other videos. On the other hand, unstructured data streams like Twitter contain much more irrelevant information, but can enable us to extract a greater amount of activities limited only by what the natural language offers. Apart from extracting the activities, we will be able to relate the entities (like TV programme and channel names). A user profile could also be partially generated from a user's activity frequency as well as the users they are following and the hash tags used.

Another part of the project will cover finding ways of measuring the accuracy and effectiveness of profiling a user based on those social data streams. We would like to find out how efficient browsing through different networks is when it comes to generating those profiles, both in terms of the quality of information regarding the media preferences as well as its amount relative to the amount of data collected. We will attempt to find a perfect ratio between the level of detail of the information we extract and the quality of user profiles generated. We will evaluate interest counting strategies for different types of entities recognized in various contexts.  

\section{Draft plan of work for the Twitter/Youtube project}

\subsection{16.03.2010}
\begin{itemize}
\item{Creating data scrapers for collecting data}
\item{Research into entity recognition papers (if applicable)}
\item{Begin implementing the data extraction algorithms}
\end{itemize}

\subsection{23.03.2010}
\begin{itemize}
\item{Initial results presentation.}
\item{Discussing used methods and possibilites of improving their results.}
\end{itemize}

\subsection{30.03.2010/06.04.2010}
\begin{itemize}
\item{Presenting the results of the improved methods for extracting data
from Twitter and YouTube separately.}
\end{itemize}

\subsection{13.04.2010}
\begin{itemize}
\item{Implementing tubelets (merging our implementations with the Beancounter)}
\item{Start working on the first deliverable (by comparing our results)}
\end{itemize}

\subsection{20.04.2010}
The draft of the Deliverable 1:
A comparative analysis of Twitter and Youtube streams as sources of data
regarding Art and TV preferences of their users.


\subsection{27.04.2010}
\begin{itemize}
\item{Research of various counting methods used both by NoTube as well as on
external cases (if any)}
\item{Discussing the possible use of- and choosing the methods for counting
purposes.}
\end{itemize}

\subsection{04.05.2010}
\begin{itemize}
\item{Implementing the chosen methods}
\item{Measuring effectiveness.}
\item{Initial results presentation.}
\end{itemize}

\subsection{11.05.2010}
\begin{itemize}
\item{Merging our implementations with the Beancounter (Reasonlets)}
\item{Measuring the influence of enrichment approaches on the efficiency of profile
generation methods.}
\item{Beginning work on the second deliverable.}
\end{itemize}

\subsection{18.05.2010}
The draft of the Deliverable 2:
What are the counting strategies, how can we improve them using different
enrichment methods?


\subsection{25.05.2010}
\begin{itemize}
\item{Working on the deliverables, taking the Notube team's comments and suggestions
into consideration.}
\end{itemize}


\subsection{01-15.06.2010}
\begin{itemize}
\item{Improving results of the taken approaches for both deliverables based on an
increasing amount of data collected.}
\item{Working on the final paper}
\end{itemize}

\section{YouTube information}

\begin{tabular}{l p{3cm} l p{4cm}}
Concerning & Information & Access & Description\\ \hline
Video & Title & Public API \\
Video & Published & Public API \\
Video & Updated & Public API \\
Video & Category & Public API \\
Video & Tags (keywords) & Public API \\
Video & Comments & Public API \\
Video & Permissons & Public API \\
Video & Description & Public API \\
Video & Thumbnails & Public API & Set of video's thumbnails (along with times
when taken) \\
Video & Duration & Public API \\
Video & Ratings & Public API & Best, worst and average rating, number of votes
\\
Video & Viewcount & Public API \\
Video & Favourite count & Public API \\
Video & Number of likes & Public API \\
Video & Number of dislikes & Public API \\
Video & Aspect ratio & Public API \\
Video & Related & Public API \\
Video & Responses & Public API \\
Video & Author & Public API \\

Video search & Number of results & Public API \\
Video search & Search results & Public API \\

User & Uploads & Public API \\
User & Gender & Public API \\
User & Location & Public API \\
User & Age & Public API \\
User & Contacts & Public API \\
User & Username & Public API \\
User & Subscriptions & Public API \\
User & Inbox & Public API \\
User & Favorites & Public API \\

Comment & Created & Public API \\
Comment & Updated & Public API \\
Comment & Author & Public API \\
Comment & Text & Public API \\

User's channel & Demographics (viewers' age/gender) & Screen scraping \\
User's channel & Referrers & Screen scraping \\
User's channel & Popularity across countries & Screen scraping \\
User & History & Screen scraping \\
User & Likes & Screen scraping \\
User & Issued authentication subtokens & Screen scraping \\

Video & Subtitles & OCR \\

\end{tabular}

\subsection{YouTube counting strategies}

\begin{itemize}
\item{Tags aggregation across various video sets:
\begin{itemize}
  \item{User's likes and favourites}
  \item{User's subscriptions (two-level aggregation there)}
  \item{User's history}
  \item{User's uploads}
\end{itemize}
}

\item{Similar aggregation for other entities found in videos
\begin{itemize}
  \item{Puropose of the video -- we could invent a dictionary of video purposes
  (eg. advertisements, lectures, speeches, movie fragments, family videos) and
  relate them to the videos.}
  \item{Keywords from comments -- after the aggregation and rejecting of stop
  words, this might prove userful.}
  \item{Language -- could be estimated by analysis of language of
  comments and description, location of the publisher and commenters.}
  \item{Duration -- users might prefer shorter clips. This might happen only for
  certain types of videos (lectures, advertisements).}
  \item{Freshness -- users might prefer videos uploaded more recently. This
  might be useful for example to identify "sneak peeks" for TV shows.}
  \item{Controversiality -- likes/dislikes ratio, amount of favourites per
  views.}
  \item{Second order effects -- facts determined for a video might be applicable
  also for a clip it is a response to.}
\end{itemize}
}

\item{Relating videos and channels to entities from other linked data services
\begin{itemize}
  \item{People: music artists, actors, directors, politicians, TV presenters,
  other public figures}
  \item{Places: cities, countries}
  \item{Existing works: TV programmes, movies, music tracks}
  \item{Others: musical, political, traditional and commercial events, brands}
\end{itemize}
}
\end{itemize}

\subsection{Conclusions from counting YouTube entities}
The most obvious way to get profiling information is through the use of
tags. However, tags of a single video clip can be either too numerous, making many
of them irrelevant, too sparse, nonexistent and occasionally just wrong. To avoid
that problem, we aggregates the tags across sets of video clips related to the
profiled user. User's favourites and clips from his subscriptions are good
candidates for such a set. Also, user's uploads have been considered and a
similar indexing was performed for words in comments.

As expected -- the favourites and subscriptions returned the most promising results
giving a lot of keywords actually identifying user's interests, and relatively
small amount of false positives.

\begin{tabular}{p{5cm} p{5cm}}
Sample subscription keywords aggregation & Sample comments keywords aggregation
(for the same user) \\ \hline
Smialek(39) & like(433) \\
fredrika(39) & video(356) \\
music(38) & just(356) \\
kulka(37) & love(312) \\
karin(37) & song(264) \\
songwriter(36) & good(254) \\
singer(36) & lol(235) \\
original(35) & dont(235) \\
female(34) & great(202) \\
gabriela(33) & im(200) \\
artist(32) & d(191) \\
folk(31) & awesome(189) \\
unsigned(31) & really(187) \\
acoustic(27) & amazing(176) \\
gaba(27) & think(169) \\
rock(26) & know(162) \\
guitar(23) & music(151) \\
kabarett(20) & people(151) \\
the(17) & thats(145) \\
berlin(14) & nice(133) \\
\end{tabular}

We can see that keywords from comments tend to gather rather more general
keywords, than subscription tags.

\end{document}
