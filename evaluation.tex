\section{User evalutation}
In order to get more detailed measures of our results, we performed user surveys
asking users to judge their extracted profiles. Two groups of users were chosen,
each counting about 15 persons, most of them active users of Twitter and YouTube
web services.

\subsection{The surveys}

Each person was presented a list of topics that were extracted from their online
activity and asked to mark their preference / level on interest in every one of
them. The marks ranged from 0 (dislike), through 1 (neutral) and 2 (like) up to
3 (strongly like). This set was extended with additional mark ''X'', meaning
''don't know this'', which let us quickly identify false positives that sneaked
into extracted profiles.

\subsection{Analyzed data description}
The activeness of users fit in relatively wide range: from 20 up to 400 tweets,
and 6-400 favourites. On average, \textit{2.69\%} of tweets were media-related.
For YouTube, videos useful for profiling formed about one tenth (\textit{9.56\%})
of the analyzed set.

\subsection{Number of false positives}
The number of false positives was astonishingly large. For some users, this
number reached more than 50\% (maximum of 73.37\% for Twitter and 83\% for
Youtube). This score makes any
recommender algorhitm, that is based on such a profile hardly of any use.
Luckily, such degenerate (more than 50\% false positives) cases were relatively
uncommon (1 and 2 in accordingly for Twitter and YouTube surveys) and happened
for users with small numbers of items in their streams.

\subsection{Preference rate accuracy}
After couting out false positives, the correctness of ratings was judged. The
number of rates guessed correctly by the Twitter profiler was \textit{76\%},
while only \textit{50\%} of YouTube rate guesses turned out to be correct. This
might mean, that the frequency of tweeting on a given subject is a better
indicator of interest than a number of videos in user's favourites feed.
