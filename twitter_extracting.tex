\section{Extracting user profile from Twitter}

In the following subsections, we will evaluate the use of entity reference extractions
mentioned in Section 3.2 when ran against the \textit{Twitter} corpus (as described in Section 3.2.1).
We will discuss the results and their usefulness for the profile generation. We will also cover problems
encountered and suggest possible solutions.

\subsection{Approach}
Since the \textit{Twitter} corpus has been selected as described in the Section 3.2.1,
we decided to cross-validate the measurements against two randomly selected halves of the corpus
to be able to minimize the overfitting of the data. By measurements, we understand methods of
entity reference extraction described in Section 3.2.

We have used vocabularies consisting of \textit{TV Actors, TV Programmes, Movies and Movie Actors} from
the \textit{FreeBase} dataset to be able to easily link the found concepts to the \textit{Open Linked Data}.

Initial results show that even using simple matching methods we are able to extract interests from
user's Twitter stream. Given that the user is a frequent user and updater of his Twitter stream, it seems
as if the average amount of tweets from which any kind of such data might be extracted oscillates around \textit{3-18\%}.

However, there is a great number of entity names (mostly TV Shows) that create noise around the results (shows such as \textit{Me too}). Removing those false positives has a crucial effect on the eventual accuracy of a Twitter-based profiler.

\subsection{Results}
In this section we present results of locating references to entities using different methods (as described in Section 3.2).
In each paragraph we present results for both halves of the Corpus, which we will refer to as \textit{Corpus 1} and
\textit{Corpus 2}

\paragraph{Full name matching}
Mentions a full name (for all actors and also TV shows/movies titles longer
than one word).

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{4cm} | p{2cm} | p{1cm}| p{2cm} | } \hline
      Entity (average) & Corpus 1 & & Corpus 2 \\ \hline
      TV Shows & 1.24\% & & 1.76\% \\ \hline
      TV Actors & 0.41\% & & 0.00\% \\ \hline
      Movies & 1.92\% & & 1.69\% \\ \hline
      Movie actors & 0.74\% & & 0.21\% \\ \hline
    \end{tabular}
    \caption{Average ratio of tweets with entities found to all tweets for different kinds of entities using full-name matching.}
  \end{table}
\end{center}

This score should be considered a baseline for further research. Those low scores seem to indicate
that mentioning those entity names is a sign of interest.

\paragraph{Matching twitter usernames}
Due to poor availability of Twitter usernames for various entities (we were able to locate less than 200 Twitter
usernames related to TV media), this approach seems not to be effective. Including those usernames adding them to the pool,
has brought extremely little (0.02\% in on of the corpuses for TV Shows) to almost none increase in the results.

\paragraph{Matching title acronyms}
Only entities with a title with 3 or more words have been used for this measurement, since searching
for smaller acronyms has generated a great amount of noise in the results.

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{4cm} | p{2cm} | p{1cm}| p{2cm} | } \hline
      Entity (average) & Corpus 1 & & Corpus 2 \\ \hline
      TV Shows & 3.07\% & & 2.17\% \\ \hline
      Movies & 2.01\% & & 2.33\% \\ \hline
    \end{tabular}
    \caption{Average ratio of tweets with entities found to all tweets for different kinds of entities using entity name acronym}
  \end{table}
\end{center}

We can easily spot an increase in matched entities, however there might be many
misleading acronyms created with this approach. Acronyms such as \textit{SNL}
(for \textit{Saturday Night Live} show) or  \textit{BBT} (\textit{Big Bang
Theory}) are widely used, probably even as much as the full titles. However,
if an acronym similar to a natural language word emerges (e.g.\textit{CAT}),
it will drastically increase the noise generated. By the matching algorithms
(thus the greatly increased percentage of tweets found). This problem might
partially be solved by the false positives avoiding methods, which we discuss later.

\paragraph{Matching name converted to a Hashtag form}
For this measurement, all entities' names have been converted to a Hashtag form (as described
in Section 3.2). In this experiment, also one-word entity names have been used.

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{4cm} | p{2cm} | p{1cm}| p{2cm} | } \hline
      Entity (average) & Corpus 1 & & Corpus 2 \\ \hline
      TV Shows & 1.18\% & & 2.21 \% \\ \hline
      TV Actors & 0.00\% & & 0.03\% \\ \hline
      Movies & 2.49\% & & 3.12\% \\ \hline
      Movie actors & 0.67\% & & 0.09\% \\ \hline
    \end{tabular}
    \caption{Average ratio of tweets with entities found to all tweets for different kinds of entities using Hashtag formed from the entity name}
  \end{table}
\end{center}

We can easily notice how the person-based entities have either noted a smaller
occurrence rate and title-based ones have improved. This may be related to the
fact that people usually create hashtags based on a more general entity (such as
a movie) rather then it's specific parts (such as actors that play in it)
when expressing their opinion.

\paragraph{Usage of activity verbs}
A rather small activity verbs vocabulary has been used.
\\ Below is a figure showing percentage of tweets using an activity verb
and a entity name (full match) out of all that have been matched with an
entity's name (hence the greater percentage scores).

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{4cm} | p{2cm} | p{1cm}| p{2cm} | } \hline
      Entity (average) & Corpus 1 & & Corpus 2 \\ \hline
      Movies & 37.4\% & & 24.3\% \\ \hline
      TV Shows & 21.2\% & & 13.4\% \\ \hline
      TV Actors & 1.3\% & & 0.6\% \\ \hline
      Movie actors & 2.1\% & & 0.0\% \\ \hline
    \end{tabular}
    \caption{Average ratio of tweets with activity verbs found to all tweets with entity references}
  \end{table}
\end{center}

As we can see, the activity verbs are very unlikely to be occurring next to
person-based entities. However, activity verbs are much more popular with both
Movies and TV Shows, which originates from the very idea of Twitter as
updating statuses with information on what the user is currently doing rather
than expressing their opinions on various subjects.

\paragraph{Usage of preference verbs}
Two sets of preference have been used: \textit{positive and negative}

The figure below shows the general use of preference verbs with occurrences of
mentions.

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{4cm} | p{2cm} | p{1cm}| p{2cm} | } \hline
      Entity (average) & Corpus 1 & & Corpus 2 \\ \hline
      TV Shows & 7.4\% & & 6.3\% \\ \hline
      Movies & 9.1\% & & 8.4\% \\ \hline
      TV Actors & 0.0\% & & 0.9\% \\ \hline
      Movie actors & 1.2\% & & 2.7\% \\ \hline
    \end{tabular}
    \caption{Average ratio of tweets with preference verbs found to all tweets with entity references}
  \end{table}
\end{center}

And a positive-to-negative preference ratio:

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{3cm}| p{2cm} | } \hline
      Type & Amount \\ \hline
      Positive & 92\% \\ \hline
      Negative & 8\% \\ \hline
    \end{tabular}
    \caption{The amount of positive and negative verbs found within the tweets with entity references found}
  \end{table}
\end{center}

The amount of preference verbs used whilst mentioning an entity is definitely
smaller compared to activity verbs. However, the Positive-to-Negative ratio most
certainly suggests that users' media preferences expressed on Twitter are
usually positive.

\paragraph{Preference towards entities followed by a user}
By gathering available Twitter usernames from the \textit{Freebase} database,
we were able to perform searches for mentions of those usernames within the followers' streams.

The following figure shows the share of different kind of mentions of the specific entity while following.

\begin{center}
  \begin{table}[h!b!p!]
    \begin{tabular}{ | p{3cm}| p{2cm} | } \hline
      Match type & Occurence \\ \hline
      Name & 0\% \\ \hline
      Hashtag & 6\% \\ \hline
      Username & 94\% \\ \hline
    \end{tabular}
    \caption{The amount of mentions by different methods of the entity being followed by a user in his stream}
  \end{table}
\end{center}

Since Twitter usernames mostly represent specific people rather than any other kinds of entities, it seems as if users mostly
mention them using their usernames rather than their names in plain or hashtag form.

However, those mentions occur relatively rarely. For a sample of 70 twitter usernames and 5 followers each
(around 4000 tweets), we were able to find out only 24 tweets (about 0.57\%) mentioning directly the people they are following.

Furthermore, following a certain entity should also be regarded just as a preference toward the topics this entity is connected to (such as
Politics for \textit{BarackObama}).

On the other hand, automated locating of more \textit{official} twitter usernames for various entities is challenging, which
limits the use of this approach.

\subsection{Avoiding accidental matches}
In order to reduce the chance accidental name matches occurring. Entity names were ran against a corpus of English texts,
ranking them by their popularity. The more often an entity name occurs in those corpora, the smaller the chance of it occurring as a name of the TV shows. In order to measure the certainty, a separate function is introduced, taking into account the following:

\begin{itemize}
  \item form of occurrence of the entity name (string match, hashtag)
  \item use of an activity verb
  \item use of a preference verb
  \item the popularity of the entity name in natural texts
\end{itemize}

This measurement will then be easily translatable into the preference weights to be recorded when profiling a user.
In order to further minimize the chance of finding an occurrence of a subject that is not describing what we are hoping is analyzing the tweet's context.
By undertaking semantic approaches we could be able to analyze different topics found in a tweet and attempt to rank their relation to the entity we are researching.

